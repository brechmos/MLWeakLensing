{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements.txt file for virtualenv\n",
    "\n",
    "Keras\n",
    "numpy\n",
    "astropy\n",
    "jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# convlulation layres to help train on image data\n",
    "from keras.layers import Conv2D, MaxPooling2D, SeparableConv2D\n",
    "\n",
    "# optimizers\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# core layers\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "def rebin(a, shape):\n",
    "    sh = shape[0],a.shape[0]//shape[0],shape[1],a.shape[1]//shape[1]\n",
    "    return a.reshape(sh).mean(-1).mean(1)\n",
    "\n",
    "def blockshaped(arr, nrows, ncols):\n",
    "    \"\"\"\n",
    "    Return an array of shape (n, nrows, ncols) where\n",
    "    n * nrows * ncols = arr.size\n",
    "\n",
    "    If arr is a 2D array, the returned array should look like n subblocks with\n",
    "    each subblock preserving the \"physical\" layout of arr.\n",
    "    \"\"\"\n",
    "    h, w = arr.shape\n",
    "    return (arr.reshape(h//nrows, nrows, -1, ncols)\n",
    "               .swapaxes(1,2)\n",
    "               .reshape(-1, nrows, ncols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display = True\n",
    "labels = ['750', '850']\n",
    "path='/Users/crjones/Documents/Science/HargisDDRF/astroNN/data/wl_maps'\n",
    "degrade=8\n",
    "nct = 9\n",
    "imsize=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0001r_0029p_0100z_og.gre.fit\n",
      "i: 1  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0002r_0029p_0100z_og.gre.fit\n",
      "i: 2  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0003r_0029p_0100z_og.gre.fit\n",
      "i: 3  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0004r_0029p_0100z_og.gre.fit\n",
      "i: 4  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0005r_0029p_0100z_og.gre.fit\n",
      "i: 5  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0006r_0029p_0100z_og.gre.fit\n",
      "i: 6  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0007r_0029p_0100z_og.gre.fit\n",
      "i: 7  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0008r_0029p_0100z_og.gre.fit\n",
      "i: 8  j: 0  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.750_4096xy_0009r_0029p_0100z_og.gre.fit\n",
      "i: 0  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0001r_0029p_0100z_og.gre.fit\n",
      "i: 1  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0002r_0029p_0100z_og.gre.fit\n",
      "i: 2  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0003r_0029p_0100z_og.gre.fit\n",
      "i: 3  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0004r_0029p_0100z_og.gre.fit\n",
      "i: 4  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0005r_0029p_0100z_og.gre.fit\n",
      "i: 5  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0006r_0029p_0100z_og.gre.fit\n",
      "i: 6  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0007r_0029p_0100z_og.gre.fit\n",
      "i: 7  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0008r_0029p_0100z_og.gre.fit\n",
      "i: 8  j: 1  name: smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.850_4096xy_0009r_0029p_0100z_og.gre.fit\n"
     ]
    }
   ],
   "source": [
    "imgs = np.zeros([2048//degrade, 2048//degrade, nct, len(labels)])\n",
    "data = []\n",
    "for j, label in enumerate(labels):\n",
    "    for i in range(nct):\n",
    "        filename = os.path.join(path, 'smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.'+label+'_4096xy_000'+ np.str(i+1) +'r_0029p_0100z_og.gre.fit')\n",
    "        if display:\n",
    "           print(\"i: %d  j: %d  name: %s\" % (i, j, 'smoothWL-conv_m-512b240_Om0.260_Ol0.740_w-1.000_ns0.960_si0.'+label+'_4096xy_000'+ np.str(i+1) +'r_0029p_0100z_og.gre.fit'))\n",
    "\n",
    "        # Read in the data and put into the imgs.\n",
    "        f = fits.open(filename)\n",
    "        \n",
    "        tt = blockshaped(rebin(f[0].data, [2048//degrade, 2048//degrade]), imsize, imsize)\n",
    "        \n",
    "        for smimg in tt:\n",
    "            data.append( (int(label), i, smimg) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_training = np.random.choice(range(len(data)), 900)\n",
    "indices_validation = np.random.choice(list(set(range(len(data))) - set(indices_training)), 50)\n",
    "indicies_testing = list( set(range(len(data))) - set(indices_training) - set(indices_validation))\n",
    "\n",
    "# \n",
    "#indices_training = [ii for ii,x in enumerate(data) if x[1] < 7]\n",
    "#indices_validation = [ii for ii,x in enumerate(data) if x[1] == 7]\n",
    "#indicies_testing = [ii for ii,x in enumerate(data) if x[1] == 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate, transpose the data to create new sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Create the 8x8 sub images from the image just read in\n",
    "training_imgs = []\n",
    "training_labels = []\n",
    "\n",
    "# Setup the shift variables (taken from 4_conv_WL notebook)\n",
    "exp_cut, exp_nshift = 3, 3\n",
    "npanelx = 2**exp_cut\n",
    "panelw = 2048//(degrade*npanelx)\n",
    "nshift = 2**exp_nshift - 1\n",
    "shiftw = panelw // npanelx\n",
    "\n",
    "# Grab the list of 8x8 sub arrays\n",
    "#temp_training_imgs = [im for ii in indices_training for im in blockshaped(data[ii][2],imsize,imsize) ]\n",
    "#temp_labels = [im for ii in indices_training for im in data[ii][0]]\n",
    "\n",
    "temp_training_imgs = []\n",
    "temp_labels = []\n",
    "for ii in indices_training:\n",
    "    temp_training_imgs.append(data[ii][2])\n",
    "    temp_labels.append(data[ii][0])\n",
    "\n",
    "# Add in all the shifts\n",
    "temp_training_imgs.extend([np.roll(x, (r,c), axis=(0,1)) \n",
    "     for x in temp_training_imgs \n",
    "     for r in [1,  5,  9, 13, 17, 21, 25] \n",
    "     for c in [1,  5,  9, 13, 17, 21, 25]\n",
    "])\n",
    "temp_labels.extend([tl \n",
    "                    for tl in temp_labels \n",
    "                    for r in [1,  5,  9, 13, 17, 21, 25] \n",
    "                    for c in [1,  5,  9, 13, 17, 21, 25]\n",
    "                   ])\n",
    "\n",
    "# Now create all the flips, rotations, transpositions etc\n",
    "training_imgs.extend(temp_training_imgs)  # sub images\n",
    "training_labels.extend(temp_labels)\n",
    "\n",
    "training_imgs.extend([x.T for x in temp_training_imgs]) # transposed sub images\n",
    "training_labels.extend(temp_labels)\n",
    "\n",
    "training_imgs.extend([np.rot90(x) for x in temp_training_imgs]) # rotated sub images\n",
    "training_labels.extend(temp_labels)\n",
    "\n",
    "training_imgs.extend([np.rot90(x, k=2) for x in temp_training_imgs]) # rotated twice sub images\n",
    "training_labels.extend(temp_labels)\n",
    "\n",
    "training_imgs.extend([np.rot90(x, k=3) for x in temp_training_imgs]) # rotated three x sub images\n",
    "training_labels.extend(temp_labels)\n",
    "\n",
    "training_imgs.extend([x[::-1] for x in temp_training_imgs]) # flip ud\n",
    "training_labels.extend(temp_labels)\n",
    "\n",
    "training_imgs.extend([x[:,::-1] for x in temp_training_imgs]) # flip lr\n",
    "training_labels.extend(temp_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now make them into a 3D array and 1D array\n",
    "X_train = np.stack(training_imgs)\n",
    "y_train = training_labels\n",
    "\n",
    "# Add dimension to X_train for keras\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, imsize, imsize)\n",
    "\n",
    "# change y_train to labels of 0 and 1 (conversion of boolean to int)\n",
    "y_train = np.array(y_train) == 850\n",
    "y_train = np_utils.to_categorical(y_train, 2)\n",
    "\n",
    "# YIKES https://github.com/ml4a/ml4a-guides/issues/10  !!!!!!!!!!!\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extend the X_test and y_test with the '850' data\n",
    "X_validation = [data[ii][2] for ii in indices_validation]\n",
    "y_validation = [data[ii][0] for ii in indices_validation]\n",
    "\n",
    "# Now make them into a 3D array and 1D array\n",
    "X_validation = np.stack(X_validation)\n",
    "y_validation = np.array(y_validation)\n",
    "\n",
    "# Add dimension to X_train for keras\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], 1, imsize, imsize)\n",
    "\n",
    "# change y_test to labels of 0 and 1 (conversion of boolean to int)\n",
    "y_validation = np.array(y_validation == 850)*1\n",
    "y_validation = np_utils.to_categorical(y_validation, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup The Keras Model\n",
    "One note on this part. There was an issue, originally of setting the filter size in this step to anything larger than (1,1).  After Googling around it appears that it had to do with an issue in Keras (described here https://github.com/ml4a/ml4a-guides/issues/10). It seems the order of the image dimensions had a conflict.  With the 2 line fix immediately above this all runs fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# input is 4D tensor with shape: (samples, channels, rows, cols)\n",
    "# output is 4D tensor with shape: (samples, filters, new_rows, new_cols)\n",
    "model.add(Conv2D(32, (5, 5), strides=(3,3), activation='relu', input_shape=(1, imsize, imsize)))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), strides=(3,3), activation='relu'))\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# MaxPooling2D is a way to reduce the number of parameters in our model by\n",
    "# sliding a 2x2 pooling filter across the previous layer and taking the max of\n",
    "# the 4 values in the 2x2 filter.\n",
    "#model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "# https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='mean_squared_logarithmic_error',\n",
    "        optimizer='adam', metrics=['accuracy', 'mae', 'mape'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 315000 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      " 10432/315000 [..............................] - ETA: 1733s - loss: 0.1221 - acc: 0.5358 - mean_absolute_error: 0.4912 - mean_absolute_percentage_error: 245590398.9693"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c195494c0e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Science/HargisDDRF/envs/keras35/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/Documents/Science/HargisDDRF/envs/keras35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Science/HargisDDRF/envs/keras35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Science/HargisDDRF/envs/keras35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Science/HargisDDRF/envs/keras35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Science/HargisDDRF/envs/keras35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Science/HargisDDRF/envs/keras35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/Documents/Science/HargisDDRF/envs/keras35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Science/HargisDDRF/envs/keras35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the testing data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extend the X_test and y_test with the '850' data\n",
    "X_test = [data[ii][2] for ii in indicies_testing]\n",
    "y_test = [data[ii][0] for ii in indicies_testing]\n",
    "\n",
    "# Now make them into a 3D array and 1D array\n",
    "X_test = np.stack(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Add dimension to X_train for keras\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, imsize, imsize)\n",
    "\n",
    "# change y_test to labels of 0 and 1 (conversion of boolean to int)\n",
    "y_test = np.array(y_test == 850)*1\n",
    "y_test = np_utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/482 [========================>.....] - ETA: 0sloss=0.8749909314377179, acc=0.6804979253112033, mean_absolute_error=0.3329025641763853, mean_absolute_percentage_error=166451300.58091286\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "names = model.metrics_names\n",
    "print('{}={}, {}={}, {}={}, {}={}'.format(names[0], scores[0], names[1], scores[1], names[2], scores[2], names[3], scores[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ws = l1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, -0.5, 2.5)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d70fcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.vstack(ws[0][0]))\n",
    "plt.colorbar()\n",
    "plt.axis('auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
